{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM0Plb4UZMT0C+gu8M39IRI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wadya-mp04/NodeJS-Blog/blob/main/notebooks/MLP_472.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8iR_zjkuHuKm",
        "outputId": "c34a688a-cb9a-495c-af0b-5c1e828a588e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms, models\n",
        "import numpy as np\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------\n",
        "# 1. Load CIFAR-10 full train and test (no transforms)\n",
        "# -------------------------------------------------\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True)\n",
        "test_dataset  = datasets.CIFAR10(root='./data', train=False, download=True)\n",
        "\n",
        "X_train_all = train_dataset.data                  # (50000, 32, 32, 3), uint8\n",
        "y_train_all = torch.tensor(train_dataset.targets)     # (50000,), ints\n",
        "\n",
        "X_test_all  = test_dataset.data                   # (10000, 32, 32, 3)\n",
        "y_test_all  = torch.tensor(test_dataset.targets)      # (10000,)\n",
        "\n",
        "class_names = train_dataset.classes\n",
        "print(\"Classes:\", class_names)\n",
        "print(\"Full train shape:\", X_train_all.shape)\n",
        "print(\"Full test shape:\", X_test_all.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSUnTaTvJmW6",
        "outputId": "c7e58454-91ef-4e8e-c2aa-29493cf1b7b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
            "Full train shape: (50000, 32, 32, 3)\n",
            "Full test shape: (10000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------\n",
        "# 2. Take 500 train and 100 test images per class\n",
        "# -------------------------------------------------\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def select_n_per_class(X, y, n_per_class, n_classes=10):\n",
        "    X_filtered = []\n",
        "    y_filtered = []\n",
        "    class_counts = [0] * n_classes\n",
        "\n",
        "    for i, label in enumerate(y):\n",
        "      label = int(label)\n",
        "      if class_counts[label] < n_per_class:\n",
        "          X_filtered.append(X[i])\n",
        "          y_filtered.append(label)\n",
        "          class_counts[label] += 1\n",
        "          if sum(class_counts) == n_per_class * n_classes:\n",
        "              break\n",
        "\n",
        "    #  lists -> NumPy arrays first (fast)\n",
        "    X_np = np.stack(X_filtered, axis=0)\n",
        "    y_np = np.array(y_filtered, dtype=np.int64)\n",
        "\n",
        "    # NumPy -> torch tensors\n",
        "    X_t = torch.from_numpy(X_np).permute(0, 3, 1, 2).float()\n",
        "    y_t = torch.from_numpy(y_np).long()\n",
        "\n",
        "    return X_t, y_t\n",
        "\n",
        "X_train, y_train = select_n_per_class(X_train_all, y_train_all, n_per_class=500)\n",
        "X_test,  y_test  = select_n_per_class(X_test_all,  y_test_all,  n_per_class=100)\n",
        "\n",
        "print(\"Train subset:\", X_train.shape, y_train.shape)\n",
        "print(\"Test subset:\",  X_test.shape,  y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zX3xKtZRBMi",
        "outputId": "8c99dbfe-098c-47dc-e465-65e8f16548cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train subset: torch.Size([5000, 3, 32, 32]) torch.Size([5000])\n",
            "Test subset: torch.Size([1000, 3, 32, 32]) torch.Size([1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -------------------------------------------------\n",
        "# 3. Define transform for ResNet-18 (resize + normalize)\n",
        "# -------------------------------------------------\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),                       # from NumPy array to PIL image\n",
        "    transforms.Resize((224, 224)),                 # ResNet-18 expects 224x224\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(                          # ImageNet mean and std\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225],\n",
        "    )\n",
        "])\n"
      ],
      "metadata": {
        "id": "Y2wv_RxnPPlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------\n",
        "# 4. Load pre-trained ResNet-18 and turn it into a feature extractor\n",
        "# -------------------------------------------------\n",
        "\n",
        "resnet18 = models.resnet18(pretrained=True)        # downloads weights if needed\n",
        "feature_extractor = nn.Sequential(*list(resnet18.children())[:-1])  # drop final layer\n",
        "feature_extractor.to(device)\n",
        "feature_extractor.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHgwbj9UT2mk",
        "outputId": "82600b81-98b7-4a02-d849-957a6b7ac12c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (2): ReLU(inplace=True)\n",
              "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (5): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (6): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (7): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------\n",
        "# 5. Function to extract 512-D features for a set of images\n",
        "# -------------------------------------------------\n",
        "\n",
        "\n",
        "def extract_features(X, model, transform, device):\n",
        "    features = []\n",
        "    with torch.no_grad():\n",
        "        for img in X:\n",
        "            img_tensor = transform(img)                # [3, 224, 224]\n",
        "            img_tensor = img_tensor.unsqueeze(0).to(device)  # [1, 3, 224, 224]\n",
        "            output = model(img_tensor)                 # [1, 512, 1, 1]\n",
        "            output = output.view(output.size(0), -1)   # [1, 512]\n",
        "            features.append(output.cpu().numpy()[0])\n",
        "    return np.array(features, dtype=np.float64)\n",
        "\n",
        "train_features = extract_features(X_train, feature_extractor, data_transform, device)\n",
        "test_features  = extract_features(X_test,  feature_extractor, data_transform, device)\n",
        "\n",
        "print(\"Train features shape:\", train_features.shape)  # (5000, 512)\n",
        "print(\"Test features shape:\",  test_features.shape)   # (1000, 512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8qKnMRLVmf4",
        "outputId": "a42c4142-05db-4ee8-c00a-85daafb64170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train features shape: (5000, 512)\n",
            "Test features shape: (1000, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------\n",
        "# 6. Use PCA to transform features from 1x512 to 1x50\n",
        "# -------------------------------------------------\n",
        "\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=50)\n",
        "train_pca = pca.fit_transform(train_features)   # (5000, 50)\n",
        "test_pca  = pca.transform(test_features)        # (1000, 50)\n",
        "# Convert PCA features back to torch tensors\n",
        "X_train_50 = torch.tensor(train_pca, dtype=torch.float32).to(device)\n",
        "X_test_50  = torch.tensor(test_pca,  dtype=torch.float32).to(device)\n",
        "\n",
        "# Move labels to device\n",
        "y_train = y_train.to(device)\n",
        "y_test  = y_test.to(device)\n",
        "\n",
        "print(X_train_50.shape, y_train.shape)  # torch.Size([5000, 50]) torch.Size([5000])\n",
        "print(X_test_50.shape,  y_test.shape)   # torch.Size([1000, 50]) torch.Size([1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsl4NtTAajyV",
        "outputId": "807c6859-3a51-415a-aa77-f96d22f2ad51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5000, 50]) torch.Size([5000])\n",
            "torch.Size([1000, 50]) torch.Size([1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------\n",
        "# 7. Build MLP model!\n",
        "# -------------------------------------------------\n",
        "class MLP (nn.Module):\n",
        "  def __init__(self,) :\n",
        "    super().__init__()\n",
        "    self.linear_layers = nn.Sequential(\n",
        "        nn.Linear(50,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,512),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,10)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.linear_layers(x)\n",
        "\n",
        "MLPModel = MLP().to(device)\n",
        "MLPModel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gm-omgiVKGSr",
        "outputId": "f60ebd65-a1b7-493a-98a4-a31f0886063f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (linear_layers): Sequential(\n",
              "    (0): Linear(in_features=50, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): ReLU()\n",
              "    (5): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------\n",
        "# 8. Define loss and optimizer function\n",
        "# -------------------------------------------------\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(params = MLPModel.parameters(), lr=0.1,momentum = 0.9)"
      ],
      "metadata": {
        "id": "ZGyBV9fRPAsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------\n",
        "# 8. Training and testing loop!!!! (for base model, as per document's instructions)\n",
        "# -------------------------------------------------\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    MLPModel.train()\n",
        "\n",
        "    logits = MLPModel(X_train_50)      # (5000, 10)\n",
        "    loss = loss_fn(logits, y_train)    # CrossEntropyLoss\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    MLPModel.eval()\n",
        "    with torch.no_grad():\n",
        "        # Train accuracy\n",
        "        train_preds = logits.argmax(dim=1)\n",
        "        train_acc = (train_preds == y_train).float().mean().item()\n",
        "\n",
        "        # Test accuracy\n",
        "        test_logits = MLPModel(X_test_50)\n",
        "        test_preds = test_logits.argmax(dim=1)\n",
        "        test_acc = (test_preds == y_test).float().mean().item()\n",
        "\n",
        "#Keep track of accuracy and lose every 10 epochs\n",
        "    if(epoch%10==0):\n",
        "      print(f\"Epoch {epoch} | Loss: {loss.item():.4f} | \"\n",
        "            f\"Train acc: {train_acc*100:.2f}% | Test acc: {test_acc*100:.2f}%\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Djzj1YLib6KR",
        "outputId": "c5c6a2c1-9c3f-4b24-f359-832a5040efa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Loss: 2.3578 | Train acc: 8.80% | Test acc: 24.80%\n",
            "Epoch 10 | Loss: 0.8833 | Train acc: 69.56% | Test acc: 61.70%\n",
            "Epoch 20 | Loss: 0.6431 | Train acc: 78.28% | Test acc: 65.90%\n",
            "Epoch 30 | Loss: 0.4734 | Train acc: 84.90% | Test acc: 66.20%\n",
            "Epoch 40 | Loss: 0.3305 | Train acc: 91.42% | Test acc: 66.00%\n",
            "Epoch 50 | Loss: 0.2159 | Train acc: 95.72% | Test acc: 65.60%\n",
            "Epoch 60 | Loss: 0.1321 | Train acc: 98.70% | Test acc: 65.90%\n",
            "Epoch 70 | Loss: 0.0786 | Train acc: 99.70% | Test acc: 65.90%\n",
            "Epoch 80 | Loss: 0.0484 | Train acc: 99.94% | Test acc: 65.70%\n",
            "Epoch 90 | Loss: 0.0322 | Train acc: 100.00% | Test acc: 65.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------\n",
        "# 9. Create model with more depth (1 more layer)\n",
        "# -------------------------------------------------\n",
        "class MLP1 (nn.Module):\n",
        "  def __init__(self,) :\n",
        "    super().__init__()\n",
        "    self.linear_layers = nn.Sequential(\n",
        "        nn.Linear(50,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,512),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,512),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,10)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.linear_layers(x)\n",
        "\n",
        "MLP1Model = MLP1().to(device)\n",
        "MLP1Model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTq_MB9xgXWp",
        "outputId": "6efb7d24-82c5-4bc4-b478-35d0935a6cd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP1(\n",
              "  (linear_layers): Sequential(\n",
              "    (0): Linear(in_features=50, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): ReLU()\n",
              "    (5): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): ReLU()\n",
              "    (8): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------\n",
        "# 10. Overwrite old optimizer and loss functions\n",
        "# -------------------------------------------------\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(params = MLP1Model.parameters(), lr=0.1,momentum = 0.9)"
      ],
      "metadata": {
        "id": "mGL4BG3lhRdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------\n",
        "# 11. Training and testing loop!!!! (for deeper model)\n",
        "# -------------------------------------------------\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # ---- TRAIN ----\n",
        "    MLP1Model.train()\n",
        "\n",
        "    logits = MLP1Model(X_train_50)      # (5000, 10)\n",
        "    loss = loss_fn(logits, y_train)    # CrossEntropyLoss\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    MLP1Model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Train accuracy\n",
        "        train_preds = logits.argmax(dim=1)\n",
        "        train_acc = (train_preds == y_train).float().mean().item()\n",
        "\n",
        "        # Test accuracy\n",
        "        test_logits = MLP1Model(X_test_50)\n",
        "        test_preds = test_logits.argmax(dim=1)\n",
        "        test_acc = (test_preds == y_test).float().mean().item()\n",
        "\n",
        "#Keep track of accuracy and lose every 10 epochs\n",
        "    if(epoch%10==0):\n",
        "      print(f\"Epoch {epoch} | Loss: {loss.item():.4f} | \"\n",
        "            f\"Train acc: {train_acc*100:.2f}% | Test acc: {test_acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgL-DQQ9glsZ",
        "outputId": "3510a0a1-af22-45f6-8ec0-850d399c0d62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Loss: 2.4011 | Train acc: 12.28% | Test acc: 28.70%\n",
            "Epoch 10 | Loss: 0.7987 | Train acc: 71.82% | Test acc: 61.50%\n",
            "Epoch 20 | Loss: 0.4740 | Train acc: 84.50% | Test acc: 65.80%\n",
            "Epoch 30 | Loss: 0.2168 | Train acc: 95.56% | Test acc: 66.80%\n",
            "Epoch 40 | Loss: 0.0710 | Train acc: 99.62% | Test acc: 66.50%\n",
            "Epoch 50 | Loss: 0.0222 | Train acc: 100.00% | Test acc: 66.70%\n",
            "Epoch 60 | Loss: 0.0096 | Train acc: 100.00% | Test acc: 65.80%\n",
            "Epoch 70 | Loss: 0.0056 | Train acc: 100.00% | Test acc: 65.80%\n",
            "Epoch 80 | Loss: 0.0040 | Train acc: 100.00% | Test acc: 65.60%\n",
            "Epoch 90 | Loss: 0.0032 | Train acc: 100.00% | Test acc: 65.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------\n",
        "# 12. Smaller layer size? (512 nodes --> 256 nodes)\n",
        "# -------------------------------------------------\n",
        "class MLP2 (nn.Module):\n",
        "  def __init__(self,) :\n",
        "    super().__init__()\n",
        "    self.linear_layers = nn.Sequential(\n",
        "        nn.Linear(50,256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256,256),\n",
        "        nn.BatchNorm1d(256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256,10)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.linear_layers(x)\n",
        "\n",
        "MLP2Model = MLP2().to(device)\n",
        "MLP2Model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_RwUm6Sh081",
        "outputId": "111b819e-15ef-4bdf-f5de-7c9c07864b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP2(\n",
              "  (linear_layers): Sequential(\n",
              "    (0): Linear(in_features=50, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "    (3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): ReLU()\n",
              "    (5): Linear(in_features=256, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------\n",
        "# 13. Overwrite old optimizer and loss functions\n",
        "# -------------------------------------------------\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(params = MLP2Model.parameters(), lr=0.1,momentum = 0.9)"
      ],
      "metadata": {
        "id": "0Q0wCXs5iGLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------\n",
        "# 14. Training and testing loop!!!! (for deeper model)\n",
        "# -------------------------------------------------\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # ---- TRAIN ----\n",
        "    MLP2Model.train()\n",
        "\n",
        "    logits = MLP2Model(X_train_50)      # (5000, 10)\n",
        "    loss = loss_fn(logits, y_train)    # CrossEntropyLoss\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    MLP2Model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Train accuracy\n",
        "        train_preds = logits.argmax(dim=1)\n",
        "        train_acc = (train_preds == y_train).float().mean().item()\n",
        "\n",
        "        # Test accuracy\n",
        "        test_logits = MLP2Model(X_test_50)\n",
        "        test_preds = test_logits.argmax(dim=1)\n",
        "        test_acc = (test_preds == y_test).float().mean().item()\n",
        "\n",
        "#Keep track of accuracy and lose every 10 epochs\n",
        "    if(epoch%10==0):\n",
        "      print(f\"Epoch {epoch} | Loss: {loss.item():.4f} | \"\n",
        "            f\"Train acc: {train_acc*100:.2f}% | Test acc: {test_acc*100:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4k7g44wmiI8u",
        "outputId": "a29bc5c2-41ab-4d2f-cab2-7df391b41e37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Loss: 2.3638 | Train acc: 10.54% | Test acc: 17.90%\n",
            "Epoch 10 | Loss: 0.9952 | Train acc: 65.24% | Test acc: 59.20%\n",
            "Epoch 20 | Loss: 0.7623 | Train acc: 73.62% | Test acc: 64.30%\n",
            "Epoch 30 | Loss: 0.6163 | Train acc: 79.22% | Test acc: 66.40%\n",
            "Epoch 40 | Loss: 0.4982 | Train acc: 83.88% | Test acc: 65.60%\n",
            "Epoch 50 | Loss: 0.3910 | Train acc: 88.54% | Test acc: 65.70%\n",
            "Epoch 60 | Loss: 0.2940 | Train acc: 92.54% | Test acc: 65.80%\n",
            "Epoch 70 | Loss: 0.2108 | Train acc: 96.08% | Test acc: 65.10%\n",
            "Epoch 80 | Loss: 0.1452 | Train acc: 98.34% | Test acc: 64.80%\n",
            "Epoch 90 | Loss: 0.0978 | Train acc: 99.42% | Test acc: 64.30%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 15. BASE MODEL EVALUATION: ACCURACY, CM, PRECISION, RECALL!!!!!!!!!\n",
        "# ================================================\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    precision_score,\n",
        "    recall_score\n",
        ")\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------------------------------------\n",
        "# 1. Generate predictions on the test set\n",
        "# ------------------------------------------------\n",
        "MLPModel.eval()\n",
        "with torch.no_grad():\n",
        "    logits_test = MLPModel(X_test_50)          # (1000, 10)\n",
        "    preds_test = logits_test.argmax(dim=1)     # torch.Size([1000])\n",
        "    preds_test_np = preds_test.cpu().numpy()\n",
        "    y_test_np = y_test.cpu().numpy()\n",
        "\n",
        "# ------------------------------------------------\n",
        "# 2. Accuracy\n",
        "# ------------------------------------------------\n",
        "accuracy = (preds_test_np == y_test_np).mean()\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# ------------------------------------------------\n",
        "# 3. Confusion Matrix\n",
        "# ------------------------------------------------\n",
        "cm = confusion_matrix(y_test_np, preds_test_np)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# If you want a heatmap:\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm, annot=False, cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix - Base MLP\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()\n",
        "\n",
        "# ------------------------------------------------\n",
        "# 4. Precision & Recall\n",
        "# ------------------------------------------------\n",
        "precision_macro = precision_score(y_test_np, preds_test_np, average=\"macro\")\n",
        "recall_macro = recall_score(y_test_np, preds_test_np, average=\"macro\")\n",
        "\n",
        "print(f\"Precision (macro): {precision_macro:.4f}\")\n",
        "print(f\"Recall (macro):    {recall_macro:.4f}\")\n",
        "\n",
        "# Per-class precision & recall\n",
        "precision_per_class = precision_score(y_test_np, preds_test_np, average=None)\n",
        "recall_per_class = recall_score(y_test_np, preds_test_np, average=None)\n",
        "\n",
        "print(\"\\nPrecision per class:\")\n",
        "print(precision_per_class)\n",
        "\n",
        "print(\"\\nRecall per class:\")\n",
        "print(recall_per_class)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NHeJZ1qgpbbv",
        "outputId": "15ce8f65-66fc-4414-8ecd-aad8a89a8235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6550\n",
            "Confusion Matrix:\n",
            " [[60  4  6  5  0  0  2  1 15  7]\n",
            " [ 2 81  1  1  1  0  0  2  4  8]\n",
            " [ 6  0 53  8  9  7  9  5  3  0]\n",
            " [ 1  2  5 50  6 20 10  4  1  1]\n",
            " [ 1  1  9 10 63  2  4  8  1  1]\n",
            " [ 0  0  6 17  4 54  9  9  0  1]\n",
            " [ 2  0  4 10  8  3 72  0  1  0]\n",
            " [ 4  1  1  4  8  6  0 70  2  4]\n",
            " [11  7  1  0  0  0  1  0 78  2]\n",
            " [ 3 12  2  0  1  1  0  2  5 74]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision (macro): 0.6536\n",
            "Recall (macro):    0.6550\n",
            "\n",
            "Precision per class:\n",
            "[0.66666667 0.75       0.60227273 0.47619048 0.63       0.58064516\n",
            " 0.6728972  0.69306931 0.70909091 0.75510204]\n",
            "\n",
            "Recall per class:\n",
            "[0.6  0.81 0.53 0.5  0.63 0.54 0.72 0.7  0.78 0.74]\n"
          ]
        }
      ]
    }
  ]
}